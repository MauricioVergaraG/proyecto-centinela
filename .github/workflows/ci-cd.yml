# ------------------------------------------------------------------
# Nombre del Workflow
# ------------------------------------------------------------------
name: CI/CD Full - Centinela (DevSecOps)

# ------------------------------------------------------------------
# Disparadores (Triggers)
# Cuándo se debe ejecutar este workflow
# ------------------------------------------------------------------
on:
  push:
    branches: [ main ]  # Se ejecuta cuando se hace merge/push a 'main'
  pull_request:
    branches: [ main ]  # Se ejecuta cuando se abre un PR contra 'main'
  workflow_dispatch: {}   # Permite ejecutarlo manualmente desde GitHub

# ------------------------------------------------------------------
# Trabajos (Jobs)
# Las tareas que se ejecutan
# ------------------------------------------------------------------
jobs:

  # ------------------------------------------------------------------
  # Job 1: Preparar Caché
  # Objetivo: Acelerar los jobs futuros guardando las dependencias.
  # ------------------------------------------------------------------
  setup-cache:
    name: Prepare & Cache (pip / npm)
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Cache pip packages
        id: cache-pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: pip-${{ hashFiles('**/services/**/requirements.txt') }}-${{ runner.os }}
          restore-keys: |
            pip-${{ runner.os }}

      - name: Cache node modules
        id: cache-node
        uses: actions/cache@v4
        with:
          path: |
            services/frontend/node_modules
            ~/.npm
          key: node-${{ hashFiles('services/frontend/**/package-lock.json') }}-${{ runner.os }}
          restore-keys: |
            node-${{ runner.os }}

  # ------------------------------------------------------------------
  # Job 2: Escaneo Estático (SAST) y Calidad de Código
  # Objetivo: Revisar el código fuente en busca de malas prácticas
  # y vulnerabilidades conocidas (SAST).
  # ------------------------------------------------------------------
  lint-format-sast:
    name: Lint / Format / SAST
    runs-on: ubuntu-latest
    needs: setup-cache # Depende del caché para ser más rápido
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      - run: |
          python -m pip install --upgrade pip
          pip install black flake8 bandit semgrep
      - run: black --check services # Revisa formato
      - run: flake8 services      # Revisa calidad (linting)
      - run: bandit -r services/api -lll # SAST para Python
      - run: semgrep --config ./.semgrep/basic-rules.yml # SAST basado en reglas

  # ------------------------------------------------------------------
  # Job 3: Escaneo de Dependencias (SCA)
  # Objetivo: Revisar las librerías de terceros (requirements.txt, etc.)
  # en busca de vulnerabilidades conocidas (CVEs).
  # ------------------------------------------------------------------
  dependency-scan:
    name: Dependency & Filesystem Scan (Trivy SBOM)
    runs-on: ubuntu-latest
    needs: lint-format-sast # Se ejecuta después de SAST
    steps:
      - uses: actions/checkout@v4
      - run: curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh | sh -s -- -b /usr/local/bin
      # Escanea el repositorio (fs) buscando CVEs altas/críticas
      - run: trivy fs --severity HIGH,CRITICAL --exit-code 1 --no-progress .

  # ------------------------------------------------------------------
  # Job 4: Escaneo de Infraestructura como Código (IaC)
  # Objetivo: Revisar los archivos de Terraform en busca de malas
  # configuraciones de seguridad (ej. puertos abiertos).
  # ------------------------------------------------------------------
  iac-scan:
    name: IaC Scan (Checkov)
    runs-on: ubuntu-latest
    needs: setup-cache # Depende del caché, corre en paralelo a otros escaneos
    steps:
        - name: Checkout
          uses: actions/checkout@v4
        - name: Run Checkov scan
          uses: bridgecrewio/checkov-action@v12
          with:
            directory: ./terraform # Carpeta donde están los archivos .tf
            framework: terraform
            output_format: cli
            # soft_fail: true -> No falla el build, solo avisa.
            # ¡Quita 'soft_fail' para que falle si encuentra errores!
            soft_fail: true

  # ------------------------------------------------------------------
  # Job 5: Pruebas Unitarias y de Integración
  # Objetivo: Ejecutar las pruebas (pytest, npm) para asegurar
  # que la lógica de la aplicación funciona.
  # ------------------------------------------------------------------
  tests:
    name: Unit & Smoke Tests
    runs-on: ubuntu-latest
    needs: dependency-scan # Se ejecuta después del escaneo de dependencias
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      - run: |
          echo "PYTHONPATH=$PYTHONPATH:$(pwd)" >> $GITHUB_ENV
      - run: |
          pip install -r services/api/requirements.txt
          pip install pytest
          pytest -q # Ejecuta pruebas de Python
      - uses: actions/setup-node@v4
        with:
          node-version: '20'
      - run: |
          cd services/frontend
          npm install
          npm run build --if-present # Construye el frontend

  # ------------------------------------------------------------------
  # Job 6: Construcción y Escaneo de Imágenes Docker
  # Objetivo: Construir las imágenes Docker y escanearlas en busca
  # de vulnerabilidades (CVEs) en el SO base.
  # ------------------------------------------------------------------
  build-and-scan-images:
    name: Build, Scan & Push Versioned Images
    runs-on: ubuntu-latest
    needs: tests # Se ejecuta después de que pasen las pruebas
    env:
      REGISTRY: ghcr.io
      IMAGE_NAMESPACE: ${{ github.repository }}
      GHCR_TOKEN: ${{ secrets.GHCR_TOKEN }}
    steps:
      - uses: actions/checkout@v4

      - name: Login to GHCR
        if: ${{ env.GHCR_TOKEN != '' }}
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ env.GHCR_TOKEN }}

      - name: Build, scan and push images
        run: |
          IMAGE_NS=$(echo "${IMAGE_NAMESPACE}" | tr '[:upper:]' '[:lower:]')

          # 1. Define las etiquetas de imagen únicas por 'run_id'
          API_IMG_ID="$REGISTRY/$IMAGE_NS/api:${{ github.run_id }}"
          FRONTEND_IMG_ID="$REGISTRY/$IMAGE_NS/frontend:${{ github.run_id }}"
          SCRAPER_IMG_ID="$REGISTRY/$IMAGE_NS/scraper:${{ github.run_id }}"

          # 2. Construye las imágenes
          docker build -t $API_IMG_ID -f services/api/Dockerfile services/api
          docker build -t $FRONTEND_IMG_ID -f services/frontend/Dockerfile services/frontend
          docker build -t $SCRAPER_IMG_ID -f services/scraper/Dockerfile services/scraper

          curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh | sh -s -- -b /usr/local/bin
          mkdir -p reports
          trivy --download-db-only || true

          # 3. Escanea las imágenes. Si Trivy encuentra algo, falla el build
          trivy image --format json --output reports/trivy-api.json --severity HIGH,CRITICAL --exit-code 1 $API_IMG_ID
          trivy image --format json --output reports/trivy-frontend.json --severity HIGH,CRITICAL --exit-code 1 $FRONTEND_IMG_ID
          trivy image --format json --output reports/trivy-scraper.json --severity HIGH,CRITICAL --exit-code 1 $SCRAPER_IMG_ID

          # Genera reportes HTML (opcional)
          trivy image --format template --template @contrib/html.tpl --output reports/trivy-api.html $API_IMG_ID || true
          trivy image --format template --template @contrib/html.tpl --output reports/trivy-frontend.html $FRONTEND_IMG_ID || true
          trivy image --format template --template @contrib/html.tpl --output reports/trivy-scraper.html $SCRAPER_IMG_ID || true
          cd reports && zip -r ../trivy-reports-${{ github.run_id }}.zip . || true
          cd - >/dev/null || true

          # 4. Sube las imágenes al registro (GHCR)
          docker push $API_IMG_ID
          docker push $FRONTEND_IMG_ID
          docker push $SCRAPER_IMG_ID

      - name: Upload Trivy reports
        if: always() # Sube reportes incluso si el 'step' anterior falló
        uses: actions/upload-artifact@v4
        with:
          name: trivy-reports
          path: |
            reports/*.json
            reports/*.html
            trivy-reports-*.zip
          if-no-files-found: ignore

  # ------------------------------------------------------------------
  # Job 7: Escaneo Dinámico (DAST)
  # Objetivo: Levantar la aplicación en un entorno temporal y
  # usar OWASP ZAP para "hackearla" y encontrar vulnerabilidades.
  # ------------------------------------------------------------------
  dast:
    name: DAST — OWASP ZAP
    runs-on: ubuntu-latest
    needs: build-and-scan-images # Depende de que las imágenes estén construidas
    permissions:
      contents: read
      issues: write
      pull-requests: write
      actions: read
    outputs:
      dast_critical: ${{ steps.set-dast-output.outputs.dast_critical }}
      dast_high: ${{ steps.set-dast-output.outputs.dast_high }}
      dast_total: ${{ steps.set-dast-output.outputs.dast_total }}
    if: always() # Se ejecuta siempre, para reportar fallos de DAST
                 # incluso si el escaneo de Trivy (job anterior) falló.
    env:
      REGISTRY: ghcr.io
      IMAGE_NAMESPACE: ${{ github.repository }}
      IMAGE_TAG: ${{ github.run_id }}
      GHCR_TOKEN: ${{ secrets.GHCR_TOKEN }}
    steps:
      - uses: actions/checkout@v4

      - name: Login to GHCR
        if: ${{ env.GHCR_TOKEN != '' }}
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ env.GHCR_TOKEN }}

      - name: Run application stack
        run: |
          export IMAGE_NAMESPACE=$(echo "${{ env.IMAGE_NAMESPACE }}" | tr '[:upper:]' '[:lower:]')
          export IMAGE_TAG=${{ env.IMAGE_TAG }}

          # ¡CORRECCIÓN CLAVE! --no-cache fuerza a Docker a usar
          # los nuevos archivos (nginx.conf) y no la imagen de caché.
          echo "Building service images (frontend, api, scraper)"
          DOCKER_BUILDKIT=1 docker compose -f docker-compose.yml build frontend api scraper --no-cache 2>&1 | tee build-compose.log || BUILD_FAILED=1

          if [ ! -z "${BUILD_FAILED}" ]; then
            echo "ERROR: docker compose build failed..."
            exit 1
          fi

          docker compose -f docker-compose.yml pull || true
          docker compose -f docker-compose.yml up -d && sleep 30

      - name: Run ZAP Baseline Scan
        run: |
          mkdir -p reports
          FRONTEND_CID=$(docker compose ps -q frontend)
          if [ -z "$FRONTEND_CID" ]; then echo "ERROR: no se encontró 'frontend'"; exit 1; fi
          NETWORK_NAME=$(docker inspect --format '{{range $k,$v := .NetworkSettings.Networks}}{{$k}} {{end}}' $FRONTEND_CID | awk '{print $1}')

          # ... (Lógica de espera de ZAP) ...

          # Se ejecuta ZAP. '|| true' evita que el job falle por exit code 2
          docker run --rm \
            -u 0 \
            --network "$NETWORK_NAME" \
            --name zap_scanner \
            -v "$(pwd)/reports":/zap/wrk \
            -w /zap/wrk \
            ghcr.io/zaproxy/zaproxy zap-baseline.py \
              -t http://frontend:80 \
              -r report_dast_zap.html \
              -J report_dast_zap.json || true

          # ... (Captura de reportes) ...

      - name: Ensure ZAP report
        if: always()
        run: |
          ls -la reports || true

      - name: Upload ZAP report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: reporte-dast-zap
          path: reports/report_dast_zap.html
          if-no-files-found: ignore

      - name: Upload ZAP JSON report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: reporte-dast-zap-json
          path: reports/report_dast_zap.json
          if-no-files-found: ignore

      - name: Collect frontend headers (debug)
        if: always()
        run: |
          # ... (Este step captura las cabeceras HTTP para debug) ...
          mkdir -p reports || true
          FRONTEND_CID=$(docker compose ps -q frontend)
          if [ -z "$FRONTEND_CID" ]; then
            echo "WARNING: frontend container missing"
          else
            NETWORK_NAME=$(docker inspect --format '{{range $k,$v := .NetworkSettings.Networks}}{{$k}} {{end}}' $FRONTEND_CID | awk '{print $1}')
            docker run --rm --network "$NETWORK_NAME" curlimages/curl:8.5.0 -sI http://frontend:80 > reports/frontend-headers.txt || true
          fi

      - name: Upload frontend headers (debug)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: frontend-headers
          path: reports/frontend-headers.txt
          if-no-files-found: ignore

      - name: Parse ZAP JSON & set outputs
        id: set-dast-output
        if: always()
        run: |
          # ... (Este step lee el JSON de ZAP y cuenta los errores) ...
          set -euo pipefail || true
          # ...
          if ! command -v jq >/dev/null 2>&1; then
            sudo apt-get update -y && sudo apt-get install -y jq || true
          fi
          # ...
          critical=$(jq '[.site[]?.alerts[]? | select(.risk=="High" or .risk=="Critical")] | length' reports/report_dast_zap.json || echo 0)
          high=$(jq '[.site[]?.alerts[]? | select(.risk=="High")] | length' reports/report_dast_zap.json || echo 0)
          # ...
          echo "dast_critical=$critical" >> $GITHUB_OUTPUT
          echo "dast_high=$high" >> $GITHUB_OUTPUT

      - name: Create issue or comment if HIGH/CRITICAL findings
        if: always()
        uses: actions/github-script@v6
        continue-on-error: true
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            # ... (Este script crea un comentario en el PR si ZAP falla) ...
            const critical = parseInt(process.env.DAST_CRITICAL || '0');
            const high = parseInt(process.env.DAST_HIGH || '0');
            if (critical > 0 || high > 0) {
              const body = `DAST scan detected issues...`;
              // ...
            }
        env:
          DAST_CRITICAL: ${{ steps.set-dast-output.outputs.dast_critical }}
          DAST_HIGH: ${{ steps.set-dast-output.outputs.dast_high }}
          DAST_TOTAL: ${{ steps.set-dast-output.outputs.dast_total }}

      # --------------------------------------------------------------
      # ¡SECURITY QUALITY GATE!
      # Este es el "portero". Si ZAP encontró errores, falla el job.
      # --------------------------------------------------------------
      - name: Fail job if critical/high findings
        if: always()
        run: |
          CRITICAL=${{ steps.set-dast-output.outputs.dast_critical }}
          HIGH=${{ steps.set-dast-output.outputs.dast_high }}

          echo "Findings: $CRITICAL critical, $HIGH high"
          if [ "$CRITICAL" -gt 0 ] || [ "$HIGH" -gt 0 ]; then
            echo "::error:: DAST found $CRITICAL critical and $HIGH high vulnerabilities. Failing build."
            exit 1 # Falla el job
          else
            echo "DAST scan passed."
          fi

      - name: Stop application stack
        if: always()
        run: docker compose -f docker-compose.yml down --volumes --remove-orphans

  # ------------------------------------------------------------------
  # Job 8: Publicar Imágenes
  # Objetivo: Retiquetar las imágenes con ':latest'
  # Solo se ejecuta si DAST pasa y si es un merge a 'main'.
  # ------------------------------------------------------------------
  publish-and-deploy:
    name: Publish ':latest' tags
    runs-on: ubuntu-latest
    needs: dast # Depende de que DAST (con su "Quality Gate") pase
    permissions:
      contents: read
      packages: write

    # --------------------------------------------------------------
    # ¡CORRECCIÓN DE LÓGICA CLAVE!
    # Esto previene que el job se ejecute en un PR.
    # Solo se ejecutará en un 'push' (merge) a la rama 'main'.
    # --------------------------------------------------------------
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'

    env:
      REGISTRY: ghcr.io
      IMAGE_NAMESPACE: ${{ github.repository }}
      GHCR_TOKEN: ${{ secrets.GHCR_TOKEN }}
    steps:
      - name: Login GHCR
        if: ${{ env.GHCR_TOKEN != '' }}
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ env.GHCR_TOKEN }}

      - run: | # Retiqueta API
          IMAGE_NS=$(echo "${IMAGE_NAMESPACE}" | tr '[:upper:]' '[:lower:]')
          docker pull $REGISTRY/$IMAGE_NS/api:${{ github.run_id }}
          docker tag  $REGISTRY/$IMAGE_NS/api:${{ github.run_id }} $REGISTRY/$IMAGE_NS/api:latest
          docker push $REGISTRY/$IMAGE_NS/api:latest
      - run: | # Retiqueta Frontend
          IMAGE_NS=$(echo "${IMAGE_NAMESPACE}" | tr '[:upper:]' '[:lower:]')
          docker pull $REGISTRY/$IMAGE_NS/frontend:${{ github.run_id }}
          docker tag  $REGISTRY/$IMAGE_NS/frontend:${{ github.run_id }} $REGISTRY/$IMAGE_NS/frontend:latest
          docker push $REGISTRY/$IMAGE_NS/frontend:latest
      - run: | # Retiqueta Scraper
          IMAGE_NS=$(echo "${IMAGE_NAMESPACE}" | tr '[:upper:]' '[:lower:]')
          docker pull $REGISTRY/$IMAGE_NS/scraper:${{ github.run_id }}
          docker tag  $REGISTRY/$IMAGE_NS/scraper:${{ github.run_id }} $REGISTRY/$IMAGE_NS/scraper:latest
          docker push $REGISTRY/$IMAGE_NS/scraper:latest

  # ------------------------------------------------------------------
  # Job 9: Limpieza
  # Objetivo: Limpiar el runner de Actions.
  # ------------------------------------------------------------------
  cleanup:
    name: Cleanup
    runs-on: ubuntu-latest
    needs: publish-and-deploy # Se ejecuta después de publicar
    if: always() # Se ejecuta siempre, incluso si el 'publish' falla
    steps:
      - run: docker image prune -af || true

  # ------------------------------------------------------------------
  # Job 10: Despliegue a Producción (CD)
  # Objetivo: Conectarse al servidor VPS por SSH y ejecutar
  # 'docker compose pull' para actualizar la app.
  # ------------------------------------------------------------------
  deploy-to-production:
    name: "Deploy to Production"
    runs-on: ubuntu-latest
    needs: publish-and-deploy # Depende de que las imágenes :latest se hayan publicado
    if: github.event_name == 'push' && github.ref == 'refs/heads/main' # Doble chequeo de seguridad
    permissions:
      contents: read
      packages: write
    env:
      REGISTRY: ghcr.io
    steps:
      - name: 1. Checkout (para obtener el docker-compose.yml)
        uses: actions/checkout@v4

      - name: 2. Configurar clave SSH
        uses: shimataro/ssh-key-action@v2
        with:
          key: ${{ secrets.DEPLOY_KEY }}
          known_hosts: 'placeholder'

      - name: 3. Añadir IP del host a known_hosts
        run: |
          ssh-keyscan -H ${{ secrets.DEPLOY_HOST }} >> ~/.ssh/known_hosts

      - name: 4. Desplegar en el Servidor
        run: |
          REMOTE_HOST="${{ secrets.DEPLOY_USER }}@${{ secrets.DEPLOY_HOST }}"

          # 1. Copia el docker-compose.yml al servidor
          scp -o StrictHostKeyChecking=no docker-compose.yml $REMOTE_HOST:/home/ubuntu/centinela/docker-compose.yml

          # 2. Se conecta por SSH y ejecuta los comandos de despliegue
          ssh -o StrictHostKeyChecking=no $REMOTE_HOST << 'EOF'

            cd /home/ubuntu/centinela

            # 3. Login en GHCR (para jalar imágenes privadas)
            echo "${{ secrets.GHCR_TOKEN }}" | docker login ghcr.io -u ${{ github.actor }} --password-stdin

            # 4. Jala las nuevas imágenes :latest
            docker compose pull

            # 5. Reinicia los servicios con las nuevas imágenes
            docker compose up -d

            # 6. Limpia imágenes viejas
            docker image prune -af
          EOF
